---
title: "A Generic Workflow for Zero-Damage Grasping of Delicate Produce Using LLMs and Volume Estimation"
collection: conference
permalink: /publication/2025-06-01-Inprogress
excerpt: 'We propose a multimodal robotic grasping system designed for damage-free manipulation of diverse fruits and vegetables. The model integrates semantic reasoning via Large Language Models (LLMs), visual grounding through Grounding DINO, and geometric perception from point cloud data to estimate object mass and generate adaptive grasp strategies.'
date: 2025-06-01
venue: 'Inprogress'
paperurl: 'Inprogress'
citation: 'Inprogress'
---

<a href='Inprogress'>Download paper here</a>

We propose a multimodal robotic grasping system designed for damage-free manipulation of diverse fruits and vegetables. The model integrates semantic reasoning via Large Language Models (LLMs), visual grounding through Grounding DINO, and geometric perception from point cloud data to estimate object mass and generate adaptive grasp strategies. To evaluate the system’s robustness, we compare two estimation paths—pure LLM reasoning and perception-assisted inference—across 25 object types. Results show that combining LLMs with 3D perception significantly improves mass estimation accuracy and grasp stability. Among seven tested LLMs, Qwen-plus achieved the best performance with the lowest MAPE and highest grasp success rate. Despite promising results, limitations remain in density estimation precision and volume correction methods. Future work will explore visual prompting, learned correction models, and dynamic force control to further enhance safety and generalization. FQGrasp demonstrates strong potential for real-world, adaptive, and safe robotic grasping.

Recommended citation: In progress